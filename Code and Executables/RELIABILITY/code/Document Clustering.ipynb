{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import enchant\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "import enchant\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the news articles into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(\"../data/parsed_news_articles.csv\")\n",
    "df['Text'] = df['Text'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    d = enchant.Dict(\"en_GB\")\n",
    "    spcl_words = ['also','said','olive','glossary','pe','butterfly','lip']\n",
    "    spcl_names = ['bjp','shaheen','bagh',\n",
    "                  'caa','nrc','covid','coronavirus','corona','virus','pm']\n",
    "#     'modi','pm','gandhi','rahul','amit','shah','sonia','congress',\n",
    "    spcl= '[-,;@_!#$%^&*()<>?/\\|}{~:''.+\"\"]'\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens=[]\n",
    "    for token in tokens:\n",
    "        token = re.sub(spcl,'',token)\n",
    "        token = re.sub('[0-9]','',token)\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            token = token.lower()\n",
    "            if token in spcl_names:\n",
    "                filtered_tokens.append(token)\n",
    "            if (token!='') and (d.check(token)) and (token not in spcl_words):\n",
    "                filtered_tokens.append(token)\n",
    "    v = [word for word in filtered_tokens if word not in stop_words]\n",
    "    stems = [lemmatizer.lemmatize(t) for t in v]\n",
    "    temp = ' '.join(i for i in stems)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedArticles=[]\n",
    "\n",
    "for i in df.index:\n",
    "    c=preprocessor(df['Text'][i])\n",
    "    cleanedArticles.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'download time news app latest news subscribe start daily morning time newspaper order welcoming decision prime minister government introduce citizenship amendment act caa national registry citizen nrc urged union government initiate dialogue opposition party dispel doubt controversial cancelled highest decision making body account government advisory cancel mass event due covid scare nonetheless held meeting member allied unit medium resolution passed general secretary indeed troubling opposition party politicising national issue duty union clarify doubt opposition party ruling party prime minister home minister shah initiate dialogue regard functionary quick add previous effort government failed opposition party shown interest understanding need act ruling party initiate dialogue need reciprocated opposition party appear little interest talk meet passed resolution welcoming claiming gave clarity foreigner nrc gave clarity foreigner much needed along caa gave citizenship persecuted minority three neighbouring country resolution atmosphere imaginary fear confusion mind section people combine support selfish political party involved communal politics foreign force making nefarious effort spread violence anarchy across country demanded resolution investigation must taken protest appropriate action taken force trying destroy communal harmony national integrity country'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedArticles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cleaned_text']=cleanedArticles\n",
    "\n",
    "df.to_csv(\"../data/parsed_cleaned.csv\",index=None)\n",
    "\n",
    "\n",
    "caa_df = df[df['Topic Name']=='caa-nrc']\n",
    "covid_df = df[df['Topic Name']=='coronavirus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(918, 12054)\n",
      "(948, 11651)\n"
     ]
    }
   ],
   "source": [
    "articles_caa = caa_df['Cleaned_text']\n",
    "articles_covid = covid_df['Cleaned_text']\n",
    "vectorizer_caa = TfidfVectorizer()\n",
    "vectorizer_covid = TfidfVectorizer()\n",
    "tfidf_matrix_caa = vectorizer_caa.fit_transform(articles_caa)\n",
    "tfidf_matrix_covid = vectorizer_covid.fit_transform(articles_covid)\n",
    "print(tfidf_matrix_caa.shape)\n",
    "print(tfidf_matrix_covid.shape)\n",
    "terms_caa = vectorizer_caa.get_feature_names()\n",
    "terms_covid = vectorizer_covid.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 3\n",
    "km_caa = KMeans(n_clusters=num_clusters,max_iter=100)\n",
    "km_covid = KMeans(n_clusters=num_clusters,max_iter=100)\n",
    "km_caa.fit(tfidf_matrix_caa)\n",
    "km_covid.fit(tfidf_matrix_covid)\n",
    "clusters_caa = km_caa.labels_.tolist()\n",
    "clusters_covid = km_covid.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vogir\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\vogir\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "caa_df['Clusters']=clusters_caa\n",
    "covid_df['Clusters']=clusters_covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster CAA-NRC:\n",
      "Cluster 0:\n",
      "police\n",
      "protest\n",
      "protester\n",
      "woman\n",
      "bagh\n",
      "student\n",
      "shaheen\n",
      "coronavirus\n",
      "march\n",
      "people\n",
      "----------------\n",
      "Cluster 1:\n",
      "congress\n",
      "party\n",
      "bjp\n",
      "pm\n",
      "minister\n",
      "caa\n",
      "leader\n",
      "nrc\n",
      "government\n",
      "citizenship\n",
      "----------------\n",
      "Cluster 2:\n",
      "nrc\n",
      "citizenship\n",
      "caa\n",
      "government\n",
      "resolution\n",
      "state\n",
      "country\n",
      "citizen\n",
      "minister\n",
      "act\n",
      "----------------\n",
      "\n",
      "\n",
      "Top terms per cluster COVID-19:\n",
      "Cluster 0:\n",
      "case\n",
      "positive\n",
      "covid\n",
      "coronavirus\n",
      "people\n",
      "tested\n",
      "state\n",
      "virus\n",
      "health\n",
      "patient\n",
      "----------------\n",
      "Cluster 1:\n",
      "government\n",
      "virus\n",
      "coronavirus\n",
      "minister\n",
      "people\n",
      "covid\n",
      "state\n",
      "congress\n",
      "country\n",
      "worker\n",
      "----------------\n",
      "Cluster 2:\n",
      "pm\n",
      "light\n",
      "minister\n",
      "prime\n",
      "coronavirus\n",
      "people\n",
      "nation\n",
      "fund\n",
      "virus\n",
      "minute\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster CAA-NRC:\")\n",
    "order_centroids = km_caa.cluster_centers_.argsort()[:, ::-1]\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d:\" % i)\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(terms_caa[ind])\n",
    "    print(\"----------------\")\n",
    "    \n",
    "    \n",
    "print(\"\\n\\nTop terms per cluster COVID-19:\")\n",
    "order_centroids = km_covid.cluster_centers_.argsort()[:, ::-1]\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d:\" % i)\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(terms_covid[ind])\n",
    "    print(\"----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_clusters):\n",
    "    articles=[]\n",
    "    file_name = \"../data/caa_nrc_cluster_\"+str(i)+\".csv\"\n",
    "    for j in caa_df.index:\n",
    "        \n",
    "        if caa_df['Clusters'][j]==i:\n",
    "            title = caa_df['Title'][j]\n",
    "            title = re.sub('[^\\\\x00-\\\\x7F]+','', title)\n",
    "            article = caa_df['Cleaned_text'][j]\n",
    "            articles.append([title,article])\n",
    "    temp = pd.DataFrame(articles,columns=['Title','Text'])\n",
    "    temp.to_csv(file_name,index=None)\n",
    "    articles.clear()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_clusters):\n",
    "    articles=[]\n",
    "    file_name = \"../data/covid_cluster_\"+str(i)+\".csv\"\n",
    "    for j in covid_df.index:\n",
    "        \n",
    "        if covid_df['Clusters'][j]==i:\n",
    "            title = covid_df['Title'][j]\n",
    "            title = re.sub('[^\\\\x00-\\\\x7F]+','', title)\n",
    "            article = covid_df['Cleaned_text'][j]\n",
    "            articles.append([title,article])\n",
    "    temp = pd.DataFrame(articles,columns=['Title','Text'])\n",
    "    temp.to_csv(file_name,index=None)\n",
    "    articles.clear()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
