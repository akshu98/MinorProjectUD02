{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import wordnet \n",
    "from collections import Counter,OrderedDict\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import enchant\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from newspaper import Article\n",
    "import statistics\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "caacluster0=pd.DataFrame(pd.read_csv(\"../data/caa_nrc_cluster_0.csv\"))\n",
    "caacluster1=pd.DataFrame(pd.read_csv(\"../data/caa_nrc_cluster_1.csv\"))\n",
    "caacluster2=pd.DataFrame(pd.read_csv(\"../data/caa_nrc_cluster_2.csv\"))\n",
    "covidcluster0=pd.DataFrame(pd.read_csv(\"../data/covid_cluster_0.csv\"))\n",
    "covidcluster1=pd.DataFrame(pd.read_csv(\"../data/covid_cluster_1.csv\"))\n",
    "covidcluster2=pd.DataFrame(pd.read_csv(\"../data/covid_cluster_2.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "caacluster0['Text']=caacluster0['Text'].astype(str)\n",
    "caacluster1['Text']=caacluster1['Text'].astype(str)\n",
    "caacluster2['Text']=caacluster2['Text'].astype(str)\n",
    "covidcluster0['Text']=covidcluster0['Text'].astype(str)\n",
    "covidcluster1['Text']=covidcluster1['Text'].astype(str)\n",
    "covidcluster2['Text']=covidcluster2['Text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "caaArticles0=[]\n",
    "caaArticles1=[]\n",
    "caaArticles2=[]\n",
    "covidArticles0=[]\n",
    "covidArticles1=[]\n",
    "covidArticles2=[]\n",
    "for i in caacluster0.index:\n",
    "    text=caacluster0['Text'][i]\n",
    "    caaArticles0.append(text)\n",
    "for i in caacluster1.index:\n",
    "    text=caacluster1['Text'][i]\n",
    "    caaArticles1.append(text)\n",
    "for i in caacluster2.index:\n",
    "    text=caacluster2['Text'][i]\n",
    "    caaArticles2.append(text)\n",
    "for i in covidcluster0.index:\n",
    "    text=covidcluster0['Text'][i]\n",
    "    covidArticles0.append(text)\n",
    "for i in covidcluster1.index:\n",
    "    text=covidcluster1['Text'][i]\n",
    "    covidArticles1.append(text)\n",
    "for i in covidcluster2.index:\n",
    "    text=covidcluster2['Text'][i]\n",
    "    covidArticles2.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_scores(text): \n",
    "    sid_obj = SentimentIntensityAnalyzer()  \n",
    "    sentiment_dict = sid_obj.polarity_scores(text)    \n",
    "    return sentiment_dict['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "caacluster0[\"sentiment\"]=\"\"\n",
    "caacluster1[\"sentiment\"]=\"\"\n",
    "caacluster2[\"sentiment\"]=\"\"\n",
    "covidcluster0[\"sentiment\"]=\"\"\n",
    "covidcluster1[\"sentiment\"]=\"\"\n",
    "covidcluster2[\"sentiment\"]=\"\"\n",
    "\n",
    "for i in range(len(caaArticles0)):\n",
    "    article_title = caacluster0['Title'].iloc[i]\n",
    "    article_text = caacluster0['Text'].iloc[i]    \n",
    "    caacluster0['sentiment'][i] = sentiment_scores(article_text)\n",
    "for i in range(len(caaArticles1)):\n",
    "    article_title = caacluster1['Title'].iloc[i]\n",
    "    article_text = caacluster1['Text'].iloc[i]    \n",
    "    caacluster1['sentiment'][i] = sentiment_scores(article_text)\n",
    "for i in range(len(caaArticles2)):\n",
    "    article_title = caacluster2['Title'].iloc[i]\n",
    "    article_text = caacluster2['Text'].iloc[i]    \n",
    "    caacluster2['sentiment'][i] = sentiment_scores(article_text)\n",
    "for i in range(len(covidArticles0)):\n",
    "    article_title = covidcluster0['Title'].iloc[i]\n",
    "    article_text = covidcluster0['Text'].iloc[i]    \n",
    "    covidcluster0['sentiment'][i] = sentiment_scores(article_text)\n",
    "for i in range(len(covidArticles1)):\n",
    "    article_title =covidcluster1['Title'].iloc[i]\n",
    "    article_text = covidcluster1['Text'].iloc[i]    \n",
    "    covidcluster1['sentiment'][i] = sentiment_scores(article_text)\n",
    "for i in range(len(covidArticles2)):\n",
    "    article_title = covidcluster2['Title'].iloc[i]\n",
    "    article_text = covidcluster2['Text'].iloc[i]    \n",
    "    covidcluster2['sentiment'][i] = sentiment_scores(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimentcaa0=caacluster0['sentiment']\n",
    "sentimentcaa1=caacluster1['sentiment']\n",
    "sentimentcaa2=caacluster2['sentiment']\n",
    "sentimentcovid0=covidcluster0['sentiment']\n",
    "sentimentcovid1=covidcluster1['sentiment']\n",
    "sentimentcovid2=covidcluster2['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neutrality_score(articleScoreDict):\n",
    "    articleValues=list(articleScoreDict)\n",
    "    neutrality=[]\n",
    "  #  caacluster0[\"neutrality\"]=\"\"\n",
    "   # print(articleValues)\n",
    "    scaler= MinMaxScaler()\n",
    "    scaler.fit(np.asarray(articleValues))\n",
    "    a=scaler.transform(articleValues)\n",
    "    \n",
    "    mean=np.mean(a)\n",
    "   # print(mean)\n",
    "    for i in a:\n",
    "        diff=(abs(mean-i)**2)\n",
    "        neutrality.append(diff)\n",
    "    caacluster1['neutrality']=neutrality\n",
    "    \n",
    "    caacluster1.to_csv(\"../data/caa_nrc_cluster_1.csv\") \n",
    "   # caacluster1.to_csv(\"caa_nrc_cluster_1.csv\") \n",
    "   # caacluster2.to_csv(\"caa_nrc_cluster_2.csv\")\n",
    "   # covidcluster2.to_csv(\"covid_cluster_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 0.5279  0.9946 -0.9894  0.4767 -0.9169 -0.5423 -0.9846  0.9227  0.2023\n -0.9559  0.4215 -0.8957 -0.8852 -0.9399  0.9744 -0.9716  0.9711  0.6124\n  0.7845 -0.6369  0.9776  0.8678  0.9572 -0.9483  0.9982  0.6981  0.661\n  0.9793 -0.9888  0.9817  0.9793 -0.7587  0.8355  0.5228  0.9953 -0.9658\n  0.9305  0.9977  0.996  -0.962   0.9538 -0.9516 -0.9965 -0.9682 -0.9673\n -0.6808 -0.9977 -0.9493  0.0258  0.8316  0.9686 -0.9042  0.9578  0.9956\n  0.9501  0.0018  0.9325  0.9738  0.4215 -0.9781 -0.9001 -0.7906 -0.6486\n  0.9874  0.9635 -0.7184  0.9926 -0.765   0.8852  0.6852  0.9823  0.9436\n -0.4329  0.3818 -0.9945 -0.0258 -0.128   0.9706 -0.9788  0.0258  0.7506\n  0.4404 -0.9903  0.9806 -0.8057  0.9432  0.34    0.8271  0.7845 -0.9986\n  0.9723  0.8669  0.9891  0.9778  0.9287 -0.891   0.8442 -0.9246  0.7934\n -0.9859  0.969   0.9571  0.6808  0.995   0.9858 -0.5126  0.7717  0.9842\n -0.886   0.4019  0.9648 -0.9638 -0.9578 -0.6908  0.9783  0.7253 -0.5106\n  0.7906  0.8126  0.765  -0.886  -0.9816  0.9916  0.9819  0.8689  0.8074\n -0.9942 -0.4215  0.9792  0.9844  0.9844  0.994   0.8979  0.9728 -0.4215\n  0.8779  0.9732  0.9735  0.9867  0.9937 -0.7351 -0.0926  0.9705  0.9678\n -0.9524 -0.4404  0.4215  0.9842  0.4215  0.9403 -0.7717  0.8807 -0.9781\n  0.9788 -0.6249 -0.9753  0.9984 -0.3918  0.9962  0.9545 -0.9957 -0.9979\n  0.9954  0.995   0.9975  0.9962 -0.9393  0.964  -0.7783  0.9889  0.9833\n  0.9585  0.9991  0.9493 -0.9929  0.9887  0.9325 -0.8934  0.9771 -0.3818\n  0.9362 -0.6806 -0.8622 -0.7717 -0.9367  0.9863 -0.9601  0.2732 -0.8271\n  0.9719  0.9042 -0.9863 -0.8971 -0.7574 -0.9274  0.9551  0.9723 -0.9826\n  0.7269 -0.9936 -0.9881  0.7926  0.9479 -0.2023 -0.9805 -0.6124  0.8481\n  0.024   0.8555 -0.6369  0.7579 -0.9682  0.9918  0.9531 -0.9918 -0.8289\n  0.818  -0.9698 -0.9719  0.9022 -0.9962  0.8176  0.5859  0.7041  0.9954\n -0.9975 -0.9927 -0.9957 -0.8834 -0.9823 -0.9578 -0.9883 -0.2263 -0.4588\n -0.3348 -0.296  -0.9826 -0.9849  0.963  -0.9966  0.9567 -0.984   0.4215\n -0.4019 -0.9271  0.8591  0.7918 -0.2263 -0.9601 -0.3566 -0.9719  0.9997\n  0.9998 -0.9657  0.9984 -0.6336 -0.9816  0.4939  0.4993 -0.9064 -0.2401\n  0.5423  0.8378 -0.1471  0.9557 -0.921  -0.      0.9618 -0.9136  0.9774\n -0.6136  0.9788  0.9942  0.6124  0.9818 -0.8487  0.5859 -0.8176  0.9682\n  0.9756  0.9571 -0.9993 -0.5267 -0.6106].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5163722349df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mneutrality_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentimentcaa1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#computePopulationBalanceScoreHistoMean(sentimentcaa1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#computePopulationBalanceScoreHistoMean(sentimentcaa2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#computePopulationBalanceScoreHistoMean(sentimentcovid0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#computePopulationBalanceScoreHistoMean(sentimentcovid1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-c4725962f253>\u001b[0m in \u001b[0;36mneutrality_score\u001b[1;34m(articleScoreDict)\u001b[0m\n\u001b[0;32m      5\u001b[0m    \u001b[1;31m# print(articleValues)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mscaler\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticleValues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticleValues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    351\u001b[0m         X = check_array(X, copy=self.copy,\n\u001b[0;32m    352\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m                         force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    519\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 0.5279  0.9946 -0.9894  0.4767 -0.9169 -0.5423 -0.9846  0.9227  0.2023\n -0.9559  0.4215 -0.8957 -0.8852 -0.9399  0.9744 -0.9716  0.9711  0.6124\n  0.7845 -0.6369  0.9776  0.8678  0.9572 -0.9483  0.9982  0.6981  0.661\n  0.9793 -0.9888  0.9817  0.9793 -0.7587  0.8355  0.5228  0.9953 -0.9658\n  0.9305  0.9977  0.996  -0.962   0.9538 -0.9516 -0.9965 -0.9682 -0.9673\n -0.6808 -0.9977 -0.9493  0.0258  0.8316  0.9686 -0.9042  0.9578  0.9956\n  0.9501  0.0018  0.9325  0.9738  0.4215 -0.9781 -0.9001 -0.7906 -0.6486\n  0.9874  0.9635 -0.7184  0.9926 -0.765   0.8852  0.6852  0.9823  0.9436\n -0.4329  0.3818 -0.9945 -0.0258 -0.128   0.9706 -0.9788  0.0258  0.7506\n  0.4404 -0.9903  0.9806 -0.8057  0.9432  0.34    0.8271  0.7845 -0.9986\n  0.9723  0.8669  0.9891  0.9778  0.9287 -0.891   0.8442 -0.9246  0.7934\n -0.9859  0.969   0.9571  0.6808  0.995   0.9858 -0.5126  0.7717  0.9842\n -0.886   0.4019  0.9648 -0.9638 -0.9578 -0.6908  0.9783  0.7253 -0.5106\n  0.7906  0.8126  0.765  -0.886  -0.9816  0.9916  0.9819  0.8689  0.8074\n -0.9942 -0.4215  0.9792  0.9844  0.9844  0.994   0.8979  0.9728 -0.4215\n  0.8779  0.9732  0.9735  0.9867  0.9937 -0.7351 -0.0926  0.9705  0.9678\n -0.9524 -0.4404  0.4215  0.9842  0.4215  0.9403 -0.7717  0.8807 -0.9781\n  0.9788 -0.6249 -0.9753  0.9984 -0.3918  0.9962  0.9545 -0.9957 -0.9979\n  0.9954  0.995   0.9975  0.9962 -0.9393  0.964  -0.7783  0.9889  0.9833\n  0.9585  0.9991  0.9493 -0.9929  0.9887  0.9325 -0.8934  0.9771 -0.3818\n  0.9362 -0.6806 -0.8622 -0.7717 -0.9367  0.9863 -0.9601  0.2732 -0.8271\n  0.9719  0.9042 -0.9863 -0.8971 -0.7574 -0.9274  0.9551  0.9723 -0.9826\n  0.7269 -0.9936 -0.9881  0.7926  0.9479 -0.2023 -0.9805 -0.6124  0.8481\n  0.024   0.8555 -0.6369  0.7579 -0.9682  0.9918  0.9531 -0.9918 -0.8289\n  0.818  -0.9698 -0.9719  0.9022 -0.9962  0.8176  0.5859  0.7041  0.9954\n -0.9975 -0.9927 -0.9957 -0.8834 -0.9823 -0.9578 -0.9883 -0.2263 -0.4588\n -0.3348 -0.296  -0.9826 -0.9849  0.963  -0.9966  0.9567 -0.984   0.4215\n -0.4019 -0.9271  0.8591  0.7918 -0.2263 -0.9601 -0.3566 -0.9719  0.9997\n  0.9998 -0.9657  0.9984 -0.6336 -0.9816  0.4939  0.4993 -0.9064 -0.2401\n  0.5423  0.8378 -0.1471  0.9557 -0.921  -0.      0.9618 -0.9136  0.9774\n -0.6136  0.9788  0.9942  0.6124  0.9818 -0.8487  0.5859 -0.8176  0.9682\n  0.9756  0.9571 -0.9993 -0.5267 -0.6106].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "neutrality_score(sentimentcaa1)\n",
    "#computePopulationBalanceScoreHistoMean(sentimentcaa1)\n",
    "#computePopulationBalanceScoreHistoMean(sentimentcaa2)\n",
    "#computePopulationBalanceScoreHistoMean(sentimentcovid0)\n",
    "#computePopulationBalanceScoreHistoMean(sentimentcovid1)\n",
    "#computePopulationBalanceScoreHistoMean(sentimentcovid2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
