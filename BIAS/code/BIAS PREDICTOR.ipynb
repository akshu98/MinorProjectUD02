{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import enchant\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import enchant\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(\"../data/parsed_news_articles.csv\")\n",
    "df['Text'] = df['Text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    d = enchant.Dict(\"en_GB\")\n",
    "    spcl= '[-,;@_!#$%^&*()<>?/\\|}{~:''.+\"\"]'\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens=[]\n",
    "    for token in tokens:\n",
    "        token = re.sub(spcl,'',token)\n",
    "        token = re.sub('[0-9]','',token)\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            token = token.lower()\n",
    "            if (token!='') and (d.check(token)):\n",
    "                filtered_tokens.append(token)\n",
    "    v = [word for word in filtered_tokens if word not in stop_words]\n",
    "    stems = [lemmatizer.lemmatize(t) for t in v]\n",
    "    temp = ' '.join(i for i in stems)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedArticles=[]\n",
    "\n",
    "for i in df.index:\n",
    "    c=preprocessor(df['Text'][i])\n",
    "    cleanedArticles.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "713"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleanedArticles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cleaned_text']=cleanedArticles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_articles = pd.read_csv(\"../data/parsed_test_articles.csv\")\n",
    "cleanedTestArticles=[]\n",
    "\n",
    "for i in test_articles.index:\n",
    "    c=preprocessor(test_articles['Text'][i])\n",
    "    cleanedTestArticles.append(c)\n",
    "    \n",
    "test_articles['Cleaned_text']=cleanedTestArticles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sim_search(query, datai):\n",
    "    cos_sim=[]\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    dataMatrixAll = []\n",
    "    similarity_dict=dict()\n",
    "    for i in range(len(query)):\n",
    "        query_i = query[i]\n",
    "        data = [query[i]]+cleanedArticles\n",
    "        lk=test_articles['Links'][i]\n",
    "        similarity_dict[lk]=list()\n",
    "        data = [query[i]]+datai\n",
    "        dataMatrix = {}\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(data)\n",
    "        vals = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix)[0]\n",
    "        for j in range(len(data)-1):\n",
    "            dataMatrix[df.loc[df['Cleaned_text'] == datai[j], 'Links'].iloc[0]]=vals[j+1]\n",
    "        \n",
    "        key_list = list(dataMatrix.keys())\n",
    "        val_list = list(dataMatrix.values())\n",
    "        sorted_vals = sorted(vals,reverse=True)[1:6]\n",
    "        for i in sorted_vals:\n",
    "            temp=key_list[val_list.index(i)]\n",
    "            similarity_dict[lk].append(temp)\n",
    "    return similarity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_scores(text):\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "    sentiment_dict = sid_obj.polarity_scores(text)\n",
    "    return sentiment_dict['compound']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment\"]=\"\"\n",
    "for i in range(len(cleanedArticles)):\n",
    "    article_title = df['Title'].iloc[i]\n",
    "    article_body = cleanedArticles[i]\n",
    "    df['sentiment'][i] = sentiment_scores(article_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Links</th>\n",
       "      <th>Cleaned_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The Indian Express</td>\n",
       "      <td>Comprehensive employment, industrial policies ...</td>\n",
       "      <td>since the employment and unemployment figures ...</td>\n",
       "      <td>https://indianexpress.com/article/opinion/colu...</td>\n",
       "      <td>since employment unemployment figure always es...</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>The Indian Express</td>\n",
       "      <td>Explained: Is the push towards organised manuf...</td>\n",
       "      <td>For a while now, it has been suggested that In...</td>\n",
       "      <td>https://indianexpress.com/article/explained/ex...</td>\n",
       "      <td>suggested unemployment woe solved boosting man...</td>\n",
       "      <td>0.9956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>The Indian Express</td>\n",
       "      <td>It’s a wage crisis</td>\n",
       "      <td>At a deeper level, our acceptance of self-expl...</td>\n",
       "      <td>https://indianexpress.com/article/opinion/colu...</td>\n",
       "      <td>deeper level acceptance form mental bondage de...</td>\n",
       "      <td>0.9959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>The Indian Express</td>\n",
       "      <td>The rising insecurity</td>\n",
       "      <td>Much of the labour force shifting out of agric...</td>\n",
       "      <td>https://indianexpress.com/article/opinion/indi...</td>\n",
       "      <td>much labour force shifting agriculture found w...</td>\n",
       "      <td>0.9771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The Indian Express</td>\n",
       "      <td>With India facing a job crisis, we should have...</td>\n",
       "      <td>Amazon to invest USD 1 bn in digitising Indian...</td>\n",
       "      <td>https://indianexpress.com/article/opinion/colu...</td>\n",
       "      <td>amazon invest digitising file amazon invest di...</td>\n",
       "      <td>0.7922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Source                                              Title  \\\n",
       "0  The Indian Express  Comprehensive employment, industrial policies ...   \n",
       "1  The Indian Express  Explained: Is the push towards organised manuf...   \n",
       "2  The Indian Express                                 It’s a wage crisis   \n",
       "3  The Indian Express                              The rising insecurity   \n",
       "4  The Indian Express  With India facing a job crisis, we should have...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  since the employment and unemployment figures ...   \n",
       "1  For a while now, it has been suggested that In...   \n",
       "2  At a deeper level, our acceptance of self-expl...   \n",
       "3  Much of the labour force shifting out of agric...   \n",
       "4  Amazon to invest USD 1 bn in digitising Indian...   \n",
       "\n",
       "                                               Links  \\\n",
       "0  https://indianexpress.com/article/opinion/colu...   \n",
       "1  https://indianexpress.com/article/explained/ex...   \n",
       "2  https://indianexpress.com/article/opinion/colu...   \n",
       "3  https://indianexpress.com/article/opinion/indi...   \n",
       "4  https://indianexpress.com/article/opinion/colu...   \n",
       "\n",
       "                                        Cleaned_text sentiment  \n",
       "0  since employment unemployment figure always es...     0.847  \n",
       "1  suggested unemployment woe solved boosting man...    0.9956  \n",
       "2  deeper level acceptance form mental bondage de...    0.9959  \n",
       "3  much labour force shifting agriculture found w...    0.9771  \n",
       "4  amazon invest digitising file amazon invest di...    0.7922  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Indian Express\n",
      "The Wire \n",
      "The Economist\n",
      "India Times\n",
      "Republic TV\n",
      "Janta Ka Reporter\n",
      "OpIndia\n",
      "The Independent\n",
      "NDTV\n",
      "Outlook India\n",
      "News Laundry\n",
      "India Today\n",
      "Time of India\n",
      "National Herald\n",
      "The Statesman\n",
      "The Hindu\n",
      "News18\n",
      "Deccan Chronicle\n",
      "Zee News\n",
      "The Telegraph\n",
      "First Post\n",
      "DNA\n",
      "The Tribune\n",
      "Scroll.in\n",
      "Reuters\n",
      "The Financial Express\n",
      "Rajya Sabha TV\n"
     ]
    }
   ],
   "source": [
    "d=dict()\n",
    "keys = df['Source'].unique()\n",
    "for key in keys:\n",
    "    d[key]=list()\n",
    "for i in range(len(df)):\n",
    "    d[df['Source'][i]].append(df['Cleaned_text'][i])\n",
    "comparison_dict=dict()\n",
    "links = list(test_articles['Links'])\n",
    "for i in range (len(test_articles)):\n",
    "    comparison_dict[links[i]]=list()\n",
    "for source,articles in d.items():\n",
    "    print(source)\n",
    "    d2 = vectorize_sim_search(cleanedTestArticles,articles)\n",
    "    ke=list(d2.keys())\n",
    "    for key in ke:\n",
    "        comparison_dict[key].append(d2[key][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = list(comparison_dict.keys())\n",
    "sourcesl = list(d.keys())\n",
    "avg_sc = [0]*27\n",
    "for link in k:\n",
    "    for i in range(len(comparison_dict[link])):\n",
    "        avg_sc[i]=avg_sc[i]+df.loc[df['Links'] == comparison_dict[link][i], 'sentiment'].iloc[0]\n",
    "for i in range(len(avg_sc)):\n",
    "    avg_sc[i]=avg_sc[i]/29\n",
    "bias_list=[0]*27\n",
    "for i in range(len(avg_sc)):\n",
    "    if(avg_sc[i]<-0.05):\n",
    "        bias_list[i]='Left'\n",
    "    elif(avg_sc[i]>0.05):\n",
    "        bias_list[i]='Right'\n",
    "    else:\n",
    "        bias_list[i]='Center'\n",
    "bias_df = pd.DataFrame(list(zip(sourcesl, bias_list)),columns =['Source', 'Bias'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The Indian Express</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>The Wire</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>The Economist</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>India Times</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Republic TV</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Janta Ka Reporter</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>OpIndia</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>The Independent</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>NDTV</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Outlook India</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>News Laundry</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>India Today</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Time of India</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>National Herald</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>The Statesman</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>The Hindu</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>News18</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Deccan Chronicle</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Zee News</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>The Telegraph</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>First Post</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>DNA</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>The Tribune</td>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Scroll.in</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>The Financial Express</td>\n",
       "      <td>Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>Rajya Sabha TV</td>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Source    Bias\n",
       "0      The Indian Express  Center\n",
       "1               The Wire     Left\n",
       "2           The Economist   Right\n",
       "3             India Times    Left\n",
       "4             Republic TV    Left\n",
       "5       Janta Ka Reporter   Right\n",
       "6                 OpIndia   Right\n",
       "7         The Independent   Right\n",
       "8                    NDTV    Left\n",
       "9           Outlook India   Right\n",
       "10           News Laundry    Left\n",
       "11            India Today    Left\n",
       "12          Time of India    Left\n",
       "13        National Herald    Left\n",
       "14          The Statesman    Left\n",
       "15              The Hindu    Left\n",
       "16                 News18    Left\n",
       "17       Deccan Chronicle    Left\n",
       "18               Zee News   Right\n",
       "19          The Telegraph   Right\n",
       "20             First Post   Right\n",
       "21                    DNA    Left\n",
       "22            The Tribune   Right\n",
       "23              Scroll.in    Left\n",
       "24                Reuters    Left\n",
       "25  The Financial Express  Center\n",
       "26         Rajya Sabha TV    Left"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
